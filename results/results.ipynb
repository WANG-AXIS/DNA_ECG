{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uncertainty_curves(correct_mask, I, n_points=100):\n",
    "    thresholds = np.linspace(0, 1, n_points, endpoint=True)\n",
    "    Rcc, Riu, UA = np.zeros(len(thresholds)), np.zeros(len(thresholds)), np.zeros(len(thresholds))\n",
    "    I[I < 0] = 0\n",
    "    I[I > 1] = 1\n",
    "    for idx, t in enumerate(thresholds):\n",
    "        certain_mask = I <= t\n",
    "        Ncc = np.sum(correct_mask & certain_mask)\n",
    "        Nic = np.sum(~correct_mask & certain_mask)\n",
    "        Niu = np.sum(~correct_mask & ~certain_mask)\n",
    "        Ncu = np.sum(correct_mask & ~certain_mask)\n",
    "        Rcc[idx] = Ncc/(Ncc+Nic) if (Ncc+Nic)>0 else -1\n",
    "        Riu[idx] = Niu/(Niu+Nic) if (Niu+Nic)>0 else -1\n",
    "        UA[idx] = (Ncc+Niu)/(Ncc+Niu+Ncu+Nic)\n",
    "    return Rcc, Riu, UA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(ensemble_names, table_names, epsilons, attack_type, normalize_by_first_set):\n",
    "    results = []\n",
    "\n",
    "    for ensemble_name, table_name in zip(ensemble_names, table_names):\n",
    "        data_dir = f'../adv_exp_new/{ensemble_name}_{attack_type}'\n",
    "        labels = np.load(f'{data_dir}/labels.npy')\n",
    "        predictions = np.load(f'{data_dir}/predictions.npy')\n",
    "        uncertainties = np.load(f'{data_dir}/uncertainties.npy')\n",
    "\n",
    "        if normalize_by_first_set:\n",
    "            I_max, I_min = np.max(uncertainties[0]), np.min(uncertainties[0])\n",
    "        else:\n",
    "            I_max, I_min = np.max(uncertainties, axis=1), np.min(uncertainties, axis=1)\n",
    "            I_max, I_min = np.expand_dims(I_max, -1), np.expand_dims(I_min, -1)\n",
    "\n",
    "        I_norm = (uncertainties-I_min) / (I_max-I_min)\n",
    "        correct_mask = predictions == labels\n",
    "\n",
    "        for idx, epsilon in enumerate(epsilons):\n",
    "            Rcc, Riu, UA = calc_uncertainty_curves(correct_mask[idx], I_norm[idx])\n",
    "            accuracy = np.mean(correct_mask[idx])\n",
    "            Rcc_AUC, Riu_AUC, UA_AUC = Rcc[Rcc>=0].mean(), Riu[Riu>=0].mean(), UA.mean()\n",
    "            results.append({\n",
    "                'Name': table_name,\n",
    "                '$\\epsilon$': epsilon,\n",
    "                'Accuracy': accuracy,\n",
    "                r'$R_{cc}$': Rcc_AUC,\n",
    "                r'$R_{iu}$': Riu_AUC,\n",
    "                '$UA$': UA_AUC\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#China 2018\n",
    "epsilons = np.array([0, 1, 2, 4, 6, 7])/40 # from yaml files\n",
    "ensemble_names = ['cor', 'dec', 'fcor', 'fdec', 'dverge', 'cor_adv', 'dec_adv']\n",
    "table_names = ['baseline', 'dec', 'part', 'dec+part',\n",
    "                  'dverge', 'adv', 'dec+adv']\n",
    "normalize_by_first_set = True\n",
    "\n",
    "pgd_df = create_df(ensemble_names, table_names, epsilons, 'china_pgd', normalize_by_first_set)\n",
    "sap_df = create_df(ensemble_names, table_names, epsilons, 'china_sap', normalize_by_first_set)\n",
    "\n",
    "epsilons = np.array([0, 1, 2, 6, 7])/40 # from yaml files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.025, 0.05 , 0.15 , 0.175])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Physionet 2017\n",
    "epsilons = np.array([0, 10, 50, 75, 100, 150]) # from yaml files\n",
    "ensemble_names = ['cor_test_run', 'dec_test_run', 'fcor_test', 'fdec_test',\n",
    "                  'adversarial_training_test', 'dverge', 'dec_adv']\n",
    "table_names = ['baseline', 'dec', 'part', 'dec+part',\n",
    "                  'adv', 'dverge', 'dec+adv']\n",
    "normalize_by_first_set = True\n",
    "\n",
    "pgd_df = create_df(ensemble_names, table_names, epsilons, 'pgd', normalize_by_first_set)\n",
    "sap_df = create_df(ensemble_names, table_names, epsilons, 'sap', normalize_by_first_set)\n",
    "\n",
    "epsilons = np.array([0, 10, 50, 75, 100]) # from yaml files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'results_table_china.txt'\n",
    "\n",
    "num_columns = 2*len(epsilons)\n",
    "\n",
    "with open(file_name, 'w') as f:\n",
    "    # Generate the table header with the specified column span for headers\n",
    "    header = \"\\\\begin{tabular}{ c | c | c c c c | c c c c  }\\n\"\n",
    "    header += \"\\\\hline\\n\"  # Add a horizontal line after the header\n",
    "    header += \" &  & \\\\multicolumn{4}{c}{Attack Strength $\\epsilon$ (PGD)} & \\\\multicolumn{4}{c}{Attack Strength $\\epsilon$ (SAP)} \\\\\\\\ \\n\"\n",
    "    #header += \" & 0 & 10 & 50 & 75 & 100 & 10 & 50 & 75 & 100 \\\\\\\\ \\n\"  # Add another horizontal line after the headers\n",
    "    header += \" & 0 & .025 & .05 & .15 & .175 & .025 & .05 & .15 & .175 \\\\\\\\ \\n\"  # Add another horizontal line after the headers\n",
    "    f.write(header)\n",
    "    \n",
    "    for metric in ['Accuracy', r'$R_{cc}$', r'$R_{iu}$', '$UA$']:\n",
    "        line = \"\\\\hline\\n\"\n",
    "        line += f\"{metric} (\\%)\" if metric=='Accuracy' else  f\"{metric} (\\% AUC)\"\n",
    "        line += ' \\\\\\\\ \\n'\n",
    "        line += \"\\\\hline\\n\"\n",
    "        f.write(line)\n",
    "        \n",
    "        for name in table_names:\n",
    "            line = f\"{name} \"\n",
    "            for epsilon in epsilons:\n",
    "                best =  np.max(pgd_df.loc[(pgd_df['$\\epsilon$'] == epsilon), metric].values)\n",
    "                value = pgd_df.loc[(pgd_df['Name'] == name) & (pgd_df['$\\epsilon$'] == epsilon), metric].values[0]\n",
    "                if value == best:\n",
    "                    line += \"& \\\\textbf{\"\n",
    "                    line += f\"{100*value:.2f}\"\n",
    "                    line += \"} \"\n",
    "                else:\n",
    "                    line += f\"& {100*value:.2f} \"\n",
    "            for epsilon in epsilons:\n",
    "                if epsilon != 0:\n",
    "                    best =  np.max(sap_df.loc[(sap_df['$\\epsilon$'] == epsilon), metric].values)\n",
    "                    value = sap_df.loc[(sap_df['Name'] == name) & (sap_df['$\\epsilon$'] == epsilon), metric].values[0]\n",
    "                    if value == best:\n",
    "                        line += \"& \\\\textbf{\"\n",
    "                        line += f\"{100*value:.2f}\"\n",
    "                        line += \"} \"\n",
    "                    else:\n",
    "                        line += f\"& {100*value:.2f} \"\n",
    "            line += '\\\\\\\\ \\n'\n",
    "            f.write(line)\n",
    "   # f.write(\"data & data & data & data & data & data & data & data & data & data & data & data \\\\\\\\ \\n\")\n",
    "    # Add more rows of data as needed\n",
    "\n",
    "    f.write(\"\\\\hline\\n\")  # Add a final horizontal line at the bottom\n",
    "    f.write(\"\\\\end{tabular} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
